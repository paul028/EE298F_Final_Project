{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.nn import utils, functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.backends import cudnn\n",
    "from torchvision import transforms\n",
    "from dssnet import build_model, weights_init\n",
    "from loss import Loss\n",
    "from tools.visual import Viz_visdom,plot_image, make_simple_grid\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from solver import Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test(self, num, use_crf=False):\n",
    "        if use_crf: from tools.crf_process import crf\n",
    "        avg_mae, img_num = 0.0, len(self.test_dataset)\n",
    "        avg_prec, avg_recall = torch.zeros(num), torch.zeros(num)\n",
    "        with torch.no_grad():\n",
    "            for i,data in enumerate(self.test_dataset): #(img, labels) in enumerate(self.test_dataset):\n",
    "                images,labels = data['image'], data['label']\n",
    "                images = images.type(torch.cuda. FloatTensor)\n",
    "                labels= labels.type(torch.cuda.FloatTensor)\n",
    "                #images = self.transform(img).unsqueeze(0)\n",
    "                #labels = labels.unsqueeze(0)\n",
    "                shape = labels.size()[2:]\n",
    "                #print(shape)\n",
    "                images = images.to(self.device)\n",
    "                labels=labels.to(self.device)\n",
    "                prob_pred = self.net(images)\n",
    "\n",
    "                prob_pred = torch.mean(torch.cat([prob_pred[i] for i in self.select], dim=1), dim=1, keepdim=True)\n",
    "                prob_pred = F.interpolate(prob_pred, size=shape, mode='bilinear', align_corners=True).cpu().data\n",
    "                print(prob_pred[0].size())\n",
    "                result_dir='C:/Users/Paul Vincent Nonat/Documents/Graduate Student Files/results/'\n",
    "                save_image(prob_pred[0],result_dir+'result'+str(i)+'.png')\n",
    "                if use_crf:\n",
    "                    prob_pred = crf(img, prob_pred.numpy(), to_tensor=True)\n",
    "                mae = self.eval_mae(prob_pred, labels)\n",
    "                prec, recall = self.eval_pr(prob_pred, labels, num)\n",
    "                print(num)\n",
    "                print(\"[%d] mae: %.4f\" % (i, mae))\n",
    "                print(\"[%d] mae: %.4f\" % (i, mae), file=self.test_output)\n",
    "                avg_mae += mae\n",
    "                avg_prec, avg_recall = avg_prec + prec, avg_recall + recall\n",
    "        avg_mae, avg_prec, avg_recall = avg_mae / img_num, avg_prec / img_num, avg_recall / img_num\n",
    "        score = (1 + self.beta ** 2) * avg_prec * avg_recall / (self.beta ** 2 * avg_prec + avg_recall)\n",
    "        score[score != score] = 0  # delete the nan\n",
    "        print('average mae: %.4f, max fmeasure: %.4f' % (avg_mae, score.max()))\n",
    "        print('average mae: %.4f, max fmeasure: %.4f' % (avg_mae, score.max()), file=self.test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =   'C:/Users/paulvincentnonat/Documents/GitHub/Saliency_Dataset/DUTS/'\n",
    "tra_image_dir = 'DUTS-TR/DUTS-TR-Image/'\n",
    "tra_label_dir = 'DUTS-TR/DUTS-TR-Mask/'\n",
    "test_image_dir = 'DUTS-TE/DUTS-TE-Image/'\n",
    "test_label_dir = 'DUTS-TE/DUTS-TE-Mask/'\n",
    "enableInpaintAug = False\n",
    "batch_size_train=32\n",
    "batch_size_val=1\n",
    "image_ext = '.jpg'\n",
    "label_ext = '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_img_name_list = glob.glob(data_dir + tra_image_dir + '*' + image_ext)\n",
    "print(\"data_dir + tra_image_dir + '*' + image_ext: \", data_dir + tra_image_dir + '*' + image_ext)\n",
    "test_img_name_list = glob.glob(data_dir + test_image_dir + '*' + image_ext)\n",
    "print(\"data_dir + test_image_dir + '*' + image_ext: \", data_dir + test_image_dir + '*' + image_ext)\n",
    "\n",
    "tra_lbl_name_list = []\n",
    "for img_path in tra_img_name_list:\n",
    "    img_name = img_path.split(\"\\\\\")[-1]\n",
    "    aaa = img_name.split(\".\")\n",
    "    bbb = aaa[0:-1]\n",
    "    imidx = bbb[0]\n",
    "    for i in range(1,len(bbb)):\n",
    "        imidx = imidx + \".\" + bbb[i]\n",
    "    tra_lbl_name_list.append(data_dir + tra_label_dir + imidx + label_ext)\n",
    "\n",
    "test_lbl_name_list = []\n",
    "for img_path in test_img_name_list:\n",
    "    img_name = img_path.split(\"\\\\\")[-1]\n",
    "    aaa = img_name.split(\".\")\n",
    "    bbb = aaa[0:-1]\n",
    "    imidx = bbb[0]\n",
    "    for i in range(1,len(bbb)):\n",
    "        imidx = imidx + \".\" + bbb[i]\n",
    "    test_lbl_name_list.append(data_dir + test_label_dir + imidx + label_ext)\n",
    "\n",
    "print(\"---\")\n",
    "print(\"train images: \", len(tra_img_name_list))\n",
    "print(\"train labels: \", len(tra_lbl_name_list))\n",
    "print(\"---\")\n",
    "\n",
    "\n",
    "print(\"---\")\n",
    "print(\"test images: \", len(test_img_name_list))\n",
    "print(\"test labels: \", len(test_lbl_name_list))\n",
    "print(\"---\")\n",
    "\n",
    "train_num = len(tra_img_name_list)\n",
    "test_num = len(test_img_name_list)\n",
    "\n",
    "salobj_dataset = SalObjDataset(\n",
    "    img_name_list=tra_img_name_list,\n",
    "    lbl_name_list=tra_lbl_name_list,\n",
    "    transform=transforms.Compose([\n",
    "        RescaleT(256),\n",
    "        RandomCrop(224),\n",
    "        ToTensorLab(flag=0)]),\n",
    "        category=\"train\",\n",
    "        enableInpaintAug=enableInpaintAug)\n",
    "salobj_dataset_test = SalObjDataset(\n",
    "    img_name_list=test_img_name_list,\n",
    "    lbl_name_list=test_lbl_name_list,\n",
    "    transform=transforms.Compose([\n",
    "        RescaleT(256),\n",
    "        RandomCrop(224),\n",
    "        ToTensorLab(flag=0)]),\n",
    "        category=\"test\",\n",
    "        enableInpaintAug=enableInpaintAug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(salobj_dataset_test, batch_size=batch_size_val, shuffle=True, num_workers=1)\n",
    "if not os.path.exists(config.test_fold): os.mkdir(config.test_fold)\n",
    "test = Solver(None, None, test_loader, config)\n",
    "test.test(100, use_crf=config.use_crf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
